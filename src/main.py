#!/usr/bin/env python3
"""
Project Shoulder - Fixed Version
"""

import os
import sys
import base64
import subprocess

print("[DEBUG] ëª¨ë“ˆ ë¡œë”©...")

import google.generativeai as genai
from mss import mss
from PIL import Image

print("[DEBUG] ë¡œë“œ ì™„ë£Œ")


class ScreenCoach:
    def __init__(self):
        api_key = os.getenv('GOOGLE_GENERATIVE_AI_API_KEY')
        if not api_key or len(api_key) < 20:
            print("âŒ API í‚¤ê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            sys.exit(1)
        
        print(f"[DEBUG] API í‚¤ í™•ì¸ë¨: {api_key[:10]}...")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash')
        self.sct = mss()
        print("[DEBUG] ì´ˆê¸°í™” ì™„ë£Œ")

    def capture_screen(self):
        print("ðŸ“¸ í™”ë©´ ìº¡ì²˜ ì¤‘...")
        monitor = self.sct.monitors[1]
        sct_img = self.sct.grab(monitor)
        img = Image.frombytes("RGB", sct_img.size, sct_img.bgra, "raw", "BGRX")
        return img

    def analyze_screen(self, img):
        print("ðŸ§  AI ë¶„ì„ ì¤‘...")
        try:
            response = self.model.generate_content([
                "ì´ í™”ë©´ì„ ë³´ê³  ì‚¬ìš©ìžê°€ ë¬´ì—‡ì„ í•˜ë ¤ëŠ”ì§€ íŒŒì•…í•˜ê³ , ë‹¤ìŒ ë‹¨ê³„ë¥¼ í•œêµ­ì–´ë¡œ 3ë¬¸ìž¥ ì´ë‚´ë¡œ ì•ˆë‚´í•´ì¤˜.",
                img
            ])
            return response.text
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜: {e}"

    def speak(self, msg):
        subprocess.run(['say', '-v', 'Yuna', msg])

    def run(self):
        print("\n" + "="*50)
        print("ðŸŽ¯ Project Shoulder")
        print("="*50)
        print("Enter: í™”ë©´ ë¶„ì„ | q + Enter: ì¢…ë£Œ")
        print("="*50 + "\n")
        
        while True:
            try:
                user_input = input("â–¶ Enterë¥¼ ëˆŒëŸ¬ í™”ë©´ ë¶„ì„... ")
                
                if user_input.lower() == 'q':
                    print("ðŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤")
                    break
                
                img = self.capture_screen()
                result = self.analyze_screen(img)
                
                print("\n" + "â”€"*40)
                print("ðŸŽ¯ ê°€ì´ë“œ:")
                print(result)
                print("â”€"*40 + "\n")
                
                self.speak(result)
                
            except KeyboardInterrupt:
                print("\nðŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤")
                break


if __name__ == "__main__":
    ScreenCoach().run()
