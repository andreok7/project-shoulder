#!/usr/bin/env python3
"""
Project Shoulder - Simple Version (Enter key to analyze)
"""

import os
import sys
import base64
import subprocess

print("[DEBUG] ëª¨ë“ˆ ë¡œë”©...")

from google import genai
from google.genai import types
from mss import mss

print("[DEBUG] ë¡œë“œ ì™„ë£Œ")


class ScreenCoach:
    SYSTEM_PROMPT = """ë‹¹ì‹ ì€ 'ìˆ„ë”'ì…ë‹ˆë‹¤. í™”ë©´ì„ ë³´ê³  í•œêµ­ì–´ë¡œ 3ë¬¸ì¥ ì´ë‚´ë¡œ ê°€ì´ë“œí•´ì£¼ì„¸ìš”."""

    def __init__(self):
        api_key = os.getenv('GOOGLE_GENERATIVE_AI_API_KEY')
        if not api_key or len(api_key) < 20:
            print("âŒ API í‚¤ê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            sys.exit(1)
        
        print(f"[DEBUG] API í‚¤ í™•ì¸ë¨: {api_key[:10]}...")
        self.client = genai.Client(api_key=api_key)
        self.sct = mss()
        print("[DEBUG] ì´ˆê¸°í™” ì™„ë£Œ")

    def capture_screen(self):
        print("ğŸ“¸ í™”ë©´ ìº¡ì²˜ ì¤‘...")
        screenshot = self.sct.shot()
        with open(screenshot, "rb") as f:
            return base64.b64encode(f.read()).decode('utf-8')

    def analyze_screen(self, image_base64):
        print("ğŸ§  AI ë¶„ì„ ì¤‘...")
        try:
            response = self.client.models.generate_content(
                model="gemini-2.0-flash",
                contents=[
                    types.Content(
                        role="user",
                        parts=[
                            types.Part.from_text(self.SYSTEM_PROMPT),
                            types.Part.from_text("ì´ í™”ë©´ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì•ˆë‚´í•´ì£¼ì„¸ìš”."),
                            types.Part.from_bytes(
                                data=base64.b64decode(image_base64),
                                mime_type="image/png"
                            )
                        ]
                    )
                ]
            )
            return response.text
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜: {e}"

    def speak(self, msg):
        subprocess.run(['say', '-v', 'Yuna', msg])

    def run(self):
        print("\n" + "="*50)
        print("ğŸ¯ Project Shoulder")
        print("="*50)
        print("Enter: í™”ë©´ ë¶„ì„ | q + Enter: ì¢…ë£Œ")
        print("="*50 + "\n")
        
        while True:
            try:
                user_input = input("â–¶ Enterë¥¼ ëˆŒëŸ¬ í™”ë©´ ë¶„ì„... ")
                
                if user_input.lower() == 'q':
                    print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤")
                    break
                
                # í™”ë©´ ìº¡ì²˜ & ë¶„ì„
                img = self.capture_screen()
                result = self.analyze_screen(img)
                
                print("\n" + "â”€"*40)
                print("ğŸ¯ ê°€ì´ë“œ:")
                print(result)
                print("â”€"*40 + "\n")
                
                self.speak(result)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤")
                break


if __name__ == "__main__":
    ScreenCoach().run()
